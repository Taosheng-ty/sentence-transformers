{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from sentence_transformers import LoggingHandler, util\n",
    "from sentence_transformers.cross_encoder import CrossEncoder\n",
    "from sentence_transformers.cross_encoder.evaluation import CERerankingEvaluator\n",
    "from sentence_transformers import InputExample\n",
    "import logging\n",
    "from datetime import datetime\n",
    "import gzip\n",
    "import os\n",
    "import tarfile\n",
    "import tqdm\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'11pt_avg',\n",
       " 'G',\n",
       " 'P',\n",
       " 'Rndcg',\n",
       " 'Rprec',\n",
       " 'Rprec_mult',\n",
       " 'binG',\n",
       " 'bpref',\n",
       " 'gm_bpref',\n",
       " 'gm_map',\n",
       " 'infAP',\n",
       " 'iprec_at_recall',\n",
       " 'map',\n",
       " 'map_cut',\n",
       " 'ndcg',\n",
       " 'ndcg_cut',\n",
       " 'ndcg_rel',\n",
       " 'num_nonrel_judged_ret',\n",
       " 'num_q',\n",
       " 'num_rel',\n",
       " 'num_rel_ret',\n",
       " 'num_ret',\n",
       " 'recall',\n",
       " 'recip_rank',\n",
       " 'relative_P',\n",
       " 'relstring',\n",
       " 'runid',\n",
       " 'set_F',\n",
       " 'set_P',\n",
       " 'set_map',\n",
       " 'set_recall',\n",
       " 'set_relative_P',\n",
       " 'success',\n",
       " 'utility'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pytrec_eval\n",
    "pytrec_eval.supported_measures\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from itertools import count\n",
    "from collections import defaultdict\n",
    "from sentence_transformers import  LoggingHandler, SentenceTransformer, evaluation, util, models\n",
    "factory = lambda c=count(): 0\n",
    "pdict = defaultdict(factory)\n",
    "qdict = defaultdict(factory)\n",
    "qRels = defaultdict(list)\n",
    "data_folder =os.path.join(os.path.expanduser('~'), '.cache/MSMARCO')\n",
    "qrel_filepath = os.path.join(data_folder, 'qrels.train.tsv')\n",
    "with open(qrel_filepath) as fIn:\n",
    "    for line in fIn:\n",
    "        qid, _, pid, _ = line.strip().split('\\t')\n",
    "        pdict[pid]+=1\n",
    "        qdict[qid]+=1\n",
    "        qRels[int(qid)].append(int(pid))\n",
    "        \n",
    "data_folder =os.path.join(os.path.expanduser('~'), '.cache/MSMARCO')\n",
    "qrel_filepath = os.path.join(data_folder, 'queries.train.tsv')\n",
    "queriesText=defaultdict(str)\n",
    "with open(qrel_filepath) as fIn:\n",
    "    for line in fIn:\n",
    "        qid, queries = line.strip().split('\\t')\n",
    "        queriesText[qid]=queries\n",
    "model_name=\"msmarco-distilbert-base-tas-b\"\n",
    "# model_name=\"output/mse-huggingfaceHard10EpochDist/171600\"\n",
    "# model_name=\"../output/log/0\"\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "model = SentenceTransformer(model_name)\n",
    "qEmb=model.encode(list(queriesText.values()),batch_size=32,show_progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_name = args.model_name\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../output/train_bi-encoder-margin_mse-distilbert-base-uncased-batch_size_64-2022-11-30_11-40-37/20000/Eval/AggResults.jjson\n",
      "../../output/train_bi-encoder-margin_mse-distilbert-base-uncased-batch_size_64-2022-11-30_11-40-37/100000/Eval/AggResults.jjson\n",
      "../../output/train_bi-encoder-margin_mse-distilbert-base-uncased-batch_size_64-2022-11-30_11-40-37/190000/Eval/AggResults.jjson\n",
      "../../output/train_bi-encoder-margin_mse-distilbert-base-uncased-batch_size_64-2022-11-30_11-40-37/150000/Eval/AggResults.jjson\n",
      "../../output/train_bi-encoder-margin_mse-distilbert-base-uncased-batch_size_64-2022-11-30_11-40-37/10000/Eval/AggResults.jjson\n",
      "../../output/train_bi-encoder-margin_mse-distilbert-base-uncased-batch_size_64-2022-11-30_11-40-37/180000/Eval/AggResults.jjson\n",
      "../../output/train_bi-encoder-margin_mse-distilbert-base-uncased-batch_size_64-2022-11-30_11-40-37/235740/Eval/AggResults.jjson\n",
      "../../output/train_bi-encoder-margin_mse-distilbert-base-uncased-batch_size_64-2022-11-30_11-40-37/90000/Eval/AggResults.jjson\n",
      "../../output/train_bi-encoder-margin_mse-distilbert-base-uncased-batch_size_64-2022-11-30_11-40-37/230000/Eval/AggResults.jjson\n",
      "../../output/train_bi-encoder-margin_mse-distilbert-base-uncased-batch_size_64-2022-11-30_11-40-37/220000/Eval/AggResults.jjson\n",
      "../../output/train_bi-encoder-margin_mse-distilbert-base-uncased-batch_size_64-2022-11-30_11-40-37/120000/Eval/AggResults.jjson\n",
      "../../output/train_bi-encoder-margin_mse-distilbert-base-uncased-batch_size_64-2022-11-30_11-40-37/70000/Eval/AggResults.jjson\n",
      "../../output/train_bi-encoder-margin_mse-distilbert-base-uncased-batch_size_64-2022-11-30_11-40-37/30000/Eval/AggResults.jjson\n",
      "../../output/train_bi-encoder-margin_mse-distilbert-base-uncased-batch_size_64-2022-11-30_11-40-37/130000/Eval/AggResults.jjson\n",
      "../../output/train_bi-encoder-margin_mse-distilbert-base-uncased-batch_size_64-2022-11-30_11-40-37/140000/Eval/AggResults.jjson\n",
      "../../output/train_bi-encoder-margin_mse-distilbert-base-uncased-batch_size_64-2022-11-30_11-40-37/40000/Eval/AggResults.jjson\n",
      "../../output/train_bi-encoder-margin_mse-distilbert-base-uncased-batch_size_64-2022-11-30_11-40-37/200000/Eval/AggResults.jjson\n",
      "../../output/train_bi-encoder-margin_mse-distilbert-base-uncased-batch_size_64-2022-11-30_11-40-37/210000/Eval/AggResults.jjson\n",
      "../../output/train_bi-encoder-margin_mse-distilbert-base-uncased-batch_size_64-2022-11-30_11-40-37/110000/Eval/AggResults.jjson\n",
      "../../output/train_bi-encoder-margin_mse-distilbert-base-uncased-batch_size_64-2022-11-30_11-40-37/160000/Eval/AggResults.jjson\n",
      "../../output/train_bi-encoder-margin_mse-distilbert-base-uncased-batch_size_64-2022-11-30_11-40-37/60000/Eval/AggResults.jjson\n",
      "../../output/train_bi-encoder-margin_mse-distilbert-base-uncased-batch_size_64-2022-11-30_11-40-37/50000/Eval/AggResults.jjson\n",
      "../../output/train_bi-encoder-margin_mse-distilbert-base-uncased-batch_size_64-2022-11-30_11-40-37/170000/Eval/AggResults.jjson\n",
      "../../output/train_bi-encoder-margin_mse-distilbert-base-uncased-batch_size_64-2022-11-30_11-40-37/80000/Eval/AggResults.jjson\n",
      "found saved results\n",
      "iterations         0.000000\n",
      "DL19ndcg_cut_10    0.701035\n",
      "DL20ndcg_cut_10    0.710068\n",
      "sum                1.411104\n",
      "Name: (210000, 0), dtype: float64\n",
      "          iterations  DL19ndcg_cut_10  DL20ndcg_cut_10       sum\n",
      "235740 0           0         0.699026         0.706038  1.405064\n",
      "230000 0           0         0.699814         0.702072  1.401886\n",
      "220000 0           0         0.698577         0.706213  1.404790\n",
      "200000 0           0         0.693890         0.711081  1.404971\n",
      "210000 0           0         0.701035         0.710068  1.411104\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import BatchExpLaunch.results_org as rog\n",
    "import pandas as pd\n",
    "import os\n",
    "# scriptPath=os.path.dirname(os.path.abspath(__file__))\n",
    "# os.chdir(scriptPath+\"/..\")\n",
    "path_root=\"../output/mse-huggingfaceHard10EpochDist\"\n",
    "path_root=\"../output/mse-huggingfaceHard10EpochCo-con\"\n",
    "path_root=\"../../output/train_bi-encoder-margin_mse-distilbert-base-uncased-batch_size_64-2022-11-30_11-40-37\"\n",
    "# path_root=\"../../output/train_bi-encoder-mnrl-distilbert-base-uncased-margin_3.0-2022-11-30_11-40-45\"\n",
    "# OutputPath=os.path.join(path_root,\"result\")\n",
    "_,MeanResult=rog.get_result_df(path_root,rerun=True)\n",
    "Result,MeanResult=rog.get_result_df(path_root,groupby=None)\n",
    "df = pd.concat(Result, axis=0)\n",
    "df[\"sum\"]=df[\"DL19ndcg_cut_10\"]+df[\"DL20ndcg_cut_10\"]\n",
    "# print(df)\n",
    "print(df.loc[df[\"sum\"].idxmax()])\n",
    "print(df[df[\"sum\"]>1.4])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "run={\"1\":{\"1\":43,\"2\":23,\"3\":120}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating ranklists: 100%|██████████| 1/1 [00:00<00:00, 11008.67it/s]\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "from eval import runsDict2trec,runsDict2Msmarco\n",
    "outfile=\"../LogslurmRun/rnk.list\"\n",
    "\n",
    "runsDict2Msmarco(run, outfile)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['fdsa', 'fdsa', 'gfa', 'gad']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d=\"fdsa\\tfdsa\\tgfa\\tgad\"\n",
    "d.strip().split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from str2bool import str2bool\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str2bool(\"True\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-12-05 20:25:31 - Read queries: queries.dev.tsv\n",
      "2022-12-05 20:25:31 - Dev query size 6980\n",
      "2022-12-05 20:25:31 - Load qrels.dev.tsv\n",
      "6980\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy@k': {1: 0.2340974212034384,\n",
       "  3: 0.4232091690544413,\n",
       "  5: 0.5131805157593123,\n",
       "  10: 0.6151862464183381},\n",
       " 'precision@k': {10: 0.06305157593123208, 100: 0.008312320916905444},\n",
       " 'recall@k': {10: 0.6041189111747851, 100: 0.788538681948424},\n",
       " 'ndcg@k': {10: 0.40842490750190563},\n",
       " 'mrr@k': {10: 0.3506348069313686},\n",
       " 'map@k': {100: 0.3532380094198648}}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import sys\n",
    "import json\n",
    "import os\n",
    "os.chdir(\"../\")\n",
    "from collections import defaultdict\n",
    "from utils.data import loadMSCorpus,loadDevMSqueries,loadDevRelMSQrels\n",
    "# scriptPath=os.path.dirname(os.path.abspath(__file__))\n",
    "\n",
    "from eval import *\n",
    "from typing import List, Tuple, Dict, Set, Callable\n",
    "from sentence_transformers import  LoggingHandler, SentenceTransformer, evaluation, util, models\n",
    "import numpy as np\n",
    "class evaluatorSbert(evaluation.InformationRetrievalEvaluator):\n",
    "    def __init__(self,*args, **kwargs):\n",
    "        super().__init__(corpus={1:\"None\"},*args, **kwargs)\n",
    "\n",
    "    def compute_metrics(self, queries_result_dict):\n",
    "        # Init score computation values\n",
    "        num_hits_at_k = {k: 0 for k in self.accuracy_at_k}\n",
    "        precisions_at_k = {k: [] for k in self.precision_recall_at_k}\n",
    "        recall_at_k = {k: [] for k in self.precision_recall_at_k}\n",
    "        MRR = {k: 0 for k in self.mrr_at_k}\n",
    "        ndcg = {k: [] for k in self.ndcg_at_k}\n",
    "        AveP_at_k = {k: [] for k in self.map_at_k}\n",
    "\n",
    "        # Compute scores on results\n",
    "        counter=0\n",
    "        for query_itr in list(queries_result_dict.keys()):\n",
    "            counter+=1\n",
    "            query_id = query_itr\n",
    "\n",
    "            # Sort scores\n",
    "            top_hits = sorted(queries_result_dict[query_itr], key=lambda x: x['score'], reverse=True)\n",
    "            query_relevant_docs = self.relevant_docs[query_id]\n",
    "\n",
    "            # Accuracy@k - We count the result correct, if at least one relevant doc is accross the top-k documents\n",
    "            for k_val in self.accuracy_at_k:\n",
    "                for hit in top_hits[0:k_val]:\n",
    "                    if hit['corpus_id'] in query_relevant_docs:\n",
    "                        num_hits_at_k[k_val] += 1\n",
    "                        break\n",
    "\n",
    "            # Precision and Recall@k\n",
    "            for k_val in self.precision_recall_at_k:\n",
    "                num_correct = 0\n",
    "                for hit in top_hits[0:k_val]:\n",
    "                    if hit['corpus_id'] in query_relevant_docs:\n",
    "                        num_correct += 1\n",
    "\n",
    "                precisions_at_k[k_val].append(num_correct / k_val)\n",
    "                recall_at_k[k_val].append(num_correct / len(query_relevant_docs))\n",
    "\n",
    "            # MRR@k\n",
    "            for k_val in self.mrr_at_k:\n",
    "                for rank, hit in enumerate(top_hits[0:k_val]):\n",
    "                    if hit['corpus_id'] in query_relevant_docs:\n",
    "                        MRR[k_val] += 1.0 / (rank + 1)\n",
    "                        break\n",
    "\n",
    "            # NDCG@k\n",
    "            for k_val in self.ndcg_at_k:\n",
    "                predicted_relevance = [1 if top_hit['corpus_id'] in query_relevant_docs else 0 for top_hit in top_hits[0:k_val]]\n",
    "                true_relevances = [1] * len(query_relevant_docs)\n",
    "\n",
    "                ndcg_value = self.compute_dcg_at_k(predicted_relevance, k_val) / self.compute_dcg_at_k(true_relevances, k_val)\n",
    "                ndcg[k_val].append(ndcg_value)\n",
    "\n",
    "            # MAP@k\n",
    "            for k_val in self.map_at_k:\n",
    "                num_correct = 0\n",
    "                sum_precisions = 0\n",
    "\n",
    "                for rank, hit in enumerate(top_hits[0:k_val]):\n",
    "                    if hit['corpus_id'] in query_relevant_docs:\n",
    "                        num_correct += 1\n",
    "                        sum_precisions += num_correct / (rank + 1)\n",
    "\n",
    "                avg_precision = sum_precisions / min(k_val, len(query_relevant_docs))\n",
    "                AveP_at_k[k_val].append(avg_precision)\n",
    "\n",
    "        # Compute averages\n",
    "        for k in num_hits_at_k:\n",
    "            num_hits_at_k[k] /= len(self.queries)\n",
    "\n",
    "        for k in precisions_at_k:\n",
    "            precisions_at_k[k] = np.mean(precisions_at_k[k])\n",
    "\n",
    "        for k in recall_at_k:\n",
    "            recall_at_k[k] = np.mean(recall_at_k[k])\n",
    "\n",
    "        for k in ndcg:\n",
    "            ndcg[k] = np.mean(ndcg[k])\n",
    "\n",
    "        for k in MRR:\n",
    "            MRR[k] /= len(self.queries)\n",
    "\n",
    "        for k in AveP_at_k:\n",
    "            AveP_at_k[k] = np.mean(AveP_at_k[k])\n",
    "\n",
    "        print(counter)\n",
    "        return {'accuracy@k': num_hits_at_k, 'precision@k': precisions_at_k, 'recall@k': recall_at_k, 'ndcg@k': ndcg, 'mrr@k': MRR, 'map@k': AveP_at_k}\n",
    "\n",
    "\n",
    "trecRun= \"/home/collab/u1368791/largefiles/TaoFiles/sentence-transformers/examples/training/ms_marco/output/training_ms-marco_cross-encoder-v2-microsoft-MiniLM-L12-H384-uncased-2022-12-03_13-25-05/985000/Eval/MSDev/output.trec.csv\"\n",
    "trecRun = \"/home/collab/u1368791/largefiles/TaoFiles/sentence-transformers/examples/training/ms_marco/output/train_bi-encoder-margin_mse--home-collab-u1368791-largefiles-TaoFiles-sentence-transformers-examples-training-ms_marco-output-mrr0.36Biencoder-235740--batch_size_64-2022-12-03_23-48-15/350000/Eval/MSDev/output.trec.csv\"\n",
    "\n",
    "# class sbertEval()\n",
    "\n",
    "def fromTrecRuntoSbertRun(trecRun):\n",
    "    sbertRun=defaultdict(list)\n",
    "    for line in open(trecRun):\n",
    "            query_id, _, doc_id, rank, score, _ = line.strip().split(' ')\n",
    "            sbertRun[query_id].append({'corpus_id': doc_id, 'score': float(score)})\n",
    "    return sbertRun\n",
    "\n",
    "sbertRun=fromTrecRuntoSbertRun(trecRun)\n",
    "data_folder =os.path.join(os.path.expanduser('~'), '.cache/MSMARCO')\n",
    "\n",
    "dev_queries=loadDevMSqueries(data_folder)\n",
    "dev_rel_docs=loadDevRelMSQrels(data_folder,dev_queries)\n",
    "# Read passages\n",
    "# corpus=loadMSCorpus(data_folder)\n",
    "ir_evaluator = evaluatorSbert(queries=dev_queries,  relevant_docs=dev_rel_docs,\n",
    "                                                        show_progress_bar=True,\n",
    "                                                        precision_recall_at_k=[10, 100],\n",
    "                                                        name=\"msmarco dev\")\n",
    "# ir_evaluator=LoadMSDevEvaluator(data_folder)\n",
    "ir_evaluator.compute_metrics(sbertRun)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6980"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qq=list(dev_rel_docs.keys())\n",
    "len(qq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "./utils/trec_eval-9.0.7/trec_eval  -M 10 -m  recip_rank -m ndcg /home/collab/u1368791/.cache/MSMARCO/qrels.dev.tsv  /home/collab/u1368791/largefiles/TaoFiles/sentence-transformers/examples/training/ms_marco/output/train_bi-encoder-margin_mse--home-collab-u1368791-largefiles-TaoFiles-sentence-transformers-examples-training-ms_marco-output-mrr0.36Biencoder-235740--batch_size_64-2022-12-03_23-48-15/350000/Eval/MSDev/output.trec.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "./utils/trec_eval-9.0.7/trec_eval  -m  recip_rank -m ndcg_cut.10 /home/collab/u1368791/.cache/MSMARCO/qrels.dev.tsv  /home/collab/u1368791/largefiles/TaoFiles/sentence-transformers/examples/training/ms_marco/output/train_bi-encoder-margin_mse--home-collab-u1368791-largefiles-TaoFiles-sentence-transformers-examples-training-ms_marco-output-mrr0.36Biencoder-235740--batch_size_64-2022-12-03_23-48-15/350000/Eval/MSDev/output.trec.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "./utils/trec_eval-9.0.7/trec_eval  -M 10 -m  recip_rank -m ndcg /home/collab/u1368791/.cache/MSMARCO/qrels.dev.tsv  /home/collab/u1368791/largefiles/TaoFiles/sentence-transformers/examples/training/ms_marco/output/train_bi-encoder-margin_mse--home-collab-u1368791-largefiles-TaoFiles-sentence-transformers-examples-training-ms_marco-output-mrr0.36Biencoder-235740--batch_size_64-2022-12-03_23-48-15/350000/Eval/MSDev/output.trec.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "./utils/trec_eval-9.0.7/trec_eval  -M 10 -m  recip_rank -m ndcg /home/collab/u1368791/.cache/MSMARCO_DL19Pass/2019qrels-pass.txt /home/collab/u1368791/largefiles/TaoFiles/sentence-transformers/examples/training/ms_marco/output/train_bi-encoder-margin_mse--home-collab-u1368791-largefiles-TaoFiles-sentence-transformers-examples-training-ms_marco-output-mrr0.36Biencoder-235740--batch_size_64-2022-12-03_23-48-15/650000/Eval/DL19/output.ms.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "./utils/trec_eval-9.0.7/trec_eval  -m  recip_rank -m ndcg_cut.10 /home/collab/u1368791/.cache/MSMARCO_DL19Pass/2019qrels-pass.txt /home/collab/u1368791/largefiles/TaoFiles/sentence-transformers/examples/training/ms_marco/output/train_bi-encoder-margin_mse--home-collab-u1368791-largefiles-TaoFiles-sentence-transformers-examples-training-ms_marco-output-mrr0.36Biencoder-235740--batch_size_64-2022-12-03_23-48-15/650000/Eval/DL19/output.trec.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "python  ./utils/msmarco_passage_eval.py  /home/collab/u1368791/.cache/MSMARCO_DL19Pass/2019qrels-pass.txt /home/collab/u1368791/largefiles/TaoFiles/sentence-transformers/examples/training/ms_marco/output/train_bi-encoder-margin_mse--home-collab-u1368791-largefiles-TaoFiles-sentence-transformers-examples-training-ms_marco-output-mrr0.36Biencoder-235740--batch_size_64-2022-12-03_23-48-15/650000/Eval/DL19/output.ms.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "python  ./utils/evalSbert.py /home/collab/u1368791/.cache/MSMARCO_DL19Pass/2019qrels-pass.txt /home/collab/u1368791/largefiles/TaoFiles/sentence-transformers/examples/training/ms_marco/output/train_bi-encoder-margin_mse--home-collab-u1368791-largefiles-TaoFiles-sentence-transformers-examples-training-ms_marco-output-mrr0.36Biencoder-235740--batch_size_64-2022-12-03_23-48-15/650000/Eval/DL19/output.trec.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "getattr expected at least 2 arguments, got 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_4500/2145543439.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"print\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: getattr expected at least 2 arguments, got 1"
     ]
    }
   ],
   "source": [
    "tt=getattr(\"print\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'__name__': '__main__',\n",
       " '__doc__': 'Automatically created module for IPython interactive environment',\n",
       " '__package__': None,\n",
       " '__loader__': None,\n",
       " '__spec__': None,\n",
       " '__builtin__': <module 'builtins' (built-in)>,\n",
       " '__builtins__': <module 'builtins' (built-in)>,\n",
       " '_ih': ['', 'tt=getattr(\"print\")', 'tt(\"fds\")', 'globals()'],\n",
       " '_oh': {},\n",
       " '_dh': ['/home/collab/u1368791/largefiles/TaoFiles/sentence-transformers/examples/training/ms_marco/NeuralIR/drafts'],\n",
       " 'In': ['', 'tt=getattr(\"print\")', 'tt(\"fds\")', 'globals()'],\n",
       " 'Out': {},\n",
       " 'get_ipython': <bound method InteractiveShell.get_ipython of <ipykernel.zmqshell.ZMQInteractiveShell object at 0x7fd2a9571f10>>,\n",
       " 'exit': <IPython.core.autocall.ZMQExitAutocall at 0x7fd2a9598310>,\n",
       " 'quit': <IPython.core.autocall.ZMQExitAutocall at 0x7fd2a9598310>,\n",
       " '_': '',\n",
       " '__': '',\n",
       " '___': '',\n",
       " 'os': <module 'os' from '/home/collab/u1368791/anaconda3/envs/sbert/lib/python3.7/os.py'>,\n",
       " 'sys': <module 'sys' (built-in)>,\n",
       " '__vsc_ipynb_file__': '/home/collab/u1368791/largefiles/TaoFiles/sentence-transformers/examples/training/ms_marco/NeuralIR/drafts/drafts.ipynb',\n",
       " '_i': 'tt(\"fds\")',\n",
       " '_ii': 'tt=getattr(\"print\")',\n",
       " '_iii': '',\n",
       " '_i1': 'tt=getattr(\"print\")',\n",
       " '_i2': 'tt(\"fds\")',\n",
       " '_i3': 'globals()'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "globals()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_4500/214208207.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"fds\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'tt' is not defined"
     ]
    }
   ],
   "source": [
    "tt(\"fds\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.15 ('sbert': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "fbbad95d1fd649463b625dabd7122d7c40eb5198c7b04fd89c984c61c714d4ed"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
